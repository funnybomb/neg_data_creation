{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2 as pw\n",
    "from Bio import Seq\n",
    "from Bio import SeqIO \n",
    "import Bio\n",
    "from Bio.Alphabet import IUPAC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "  \n",
    "def fn_timer(function):\n",
    "    @wraps(function)\n",
    "    def function_timer(*args, **kwargs):\n",
    "        t0 = time.process_time()\n",
    "        result = function(*args, **kwargs)\n",
    "        t1 = time.process_time()\n",
    "        print (\"Total time running %s: %s seconds\" %\n",
    "            (function.__name__, str(t1-t0))\n",
    "            )\n",
    "        return result\n",
    "    return function_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot = list(SeqIO.parse('uniprot-proteome_human.fasta','fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('MKMASSLAFLLLNFHVSLLLVQLLTPCSAQFSVLGPSGPILAMVGEDADLPCHL...KSA', SingleLetterAlphabet())"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniprot[0].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in uniprot:   #\n",
    "    x = seq.id\n",
    "    seq.id = x.split(\"|\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [seq.id for seq in uniprot]\n",
    "names = [seq.name for seq in uniprot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_dict = {}\n",
    "for i in uniprot:\n",
    "    uni_dict[i.id] =i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@fn_timer\n",
    "def calc_identity_score(seq1,seq2,gap=-0.5,extend=-0.1):\n",
    "    \"\"\"\n",
    "    return seq1 seq1 pairwise identiy score\n",
    "    seq1 is positive \n",
    "    seq1 seq2 is string\n",
    "\n",
    "    Bio.pairwise2.format_alignment output:\n",
    "    MPKGKKAKG------\n",
    "      |||||||      \n",
    "    --KGKKAKGKKVAPA\n",
    "      Score=7\n",
    "      \n",
    "    alignment output: [('MPKGKKAKG------', '--KGKKAKGKKVAPA', 7.0, 0, 15)]\n",
    "    score = ali[0][2] = 7\n",
    "    \"\"\"\n",
    "    ali = pw.align.globalxs(seq1,seq2,gap,extend,score_only=True)\n",
    "    # gap penalty = -0.5 in case of cak caak score =3\n",
    "    return ali/min(len(seq1),len(seq2)) # 返回短序列的值,防止substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@fn_timer\n",
    "def window_generator(seq, window_lenth=7,step=1):\n",
    "    \"\"\"\n",
    "    return list of seq window slide\n",
    "    seq is string\n",
    "    \"\"\"\n",
    "    if len(seq) >= window_lenth:\n",
    "        return [seq[i:i+window_lenth] for i in range(0,len(seq)-window_lenth+1,step)]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '23']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_generator('123',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.pairwise2 import format_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat(nums):\n",
    "    res = []\n",
    "    for i in nums:\n",
    "        if isinstance(i, list):\n",
    "            res.extend(flat(i))\n",
    "        else:\n",
    "            res.append(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@fn_timer\n",
    "def slide_with_flank(seq,full,step=1,up_flank=6,down_flank=6,flags=0):\n",
    "    \"\"\"\n",
    "    return window slide result as list for a full str given potential sub seq and it's flank removed\n",
    "    seq=abc, full = 01234abc45678abc1234 up=1 down=1 step =1\n",
    "    result is ['012', '123', '567', '234']\n",
    "    生成一个str full 的滑动窗口自片段,去除了seq和其上下游的部分\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    window_len = len(seq)\n",
    "    coords = [i.span() for i in re.finditer(seq,full,flags)] # = search_all\n",
    "    # 处理首尾情况\n",
    "    if len(coords) == 0:\n",
    "        res.append(window_generator(full,window_lenth=window_len,step=step))\n",
    "\n",
    "    elif len(coords) == 1:\n",
    "        if (coords[0][0]-up_flank) >= 0:\n",
    "            res.append(window_generator(full[0:coords[0][0]-up_flank],\n",
    "                                        window_lenth=window_len,step=step))\n",
    "        if (coords[0][1]+down_flank) <= len(full):\n",
    "            res.append(window_generator(full[coords[0][1]+up_flank:],\n",
    "                                        window_lenth=window_len,step=step))\n",
    "    else: # len(coords) >1  \n",
    "        if (coords[0][0]-up_flank) >= 0:\n",
    "            res.append(window_generator(full[0:coords[0][0]-up_flank],\n",
    "                                        window_lenth=window_len,step=step))\n",
    "        for i in range(1,len(coords)):\n",
    "        ## 处理 1 2 之间的东西\n",
    "            if coords[i][0] - coords[i-1][1] > up_flank+down_flank+window_len:\n",
    "                res.append(window_generator(full[coords[i-1][1]+up_flank:coords[i][0]-down_flank],\n",
    "                                            window_lenth=window_len,step=step))\n",
    "                           \n",
    "        if (coords[-1][1]+down_flank) <= len(full):\n",
    "            res.append(window_generator(full[coords[-1][1]+down_flank:],\n",
    "                                        window_lenth=window_len,step=step))           \n",
    "        \n",
    "    return set(flat(res))\n",
    "    #return flat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'012', '6ra', 'raa'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_with_flank('abc','01234abc456raa78abc7779',up_flank=2,down_flank=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### @fn_timer\n",
    "\n",
    "def filter_with_identity_affinity(seq,full,identity_cutoff=0.5,step=1,up=6,down=6,flags=0):\n",
    "    \"\"\"给出full中与seq 过滤 identity/netMHC todo的片段\n",
    "    identity最低的\n",
    "    netMHC 最好的 若干 个seq 片段\n",
    "    \"\"\"\n",
    "    tmp = 1\n",
    "    out=''\n",
    "    slides = slide_with_flank(seq,full,step=step,up_flank=up,down_flank=down,flags=flags)\n",
    "    for s in slides:\n",
    "        identity_score = calc_identity_score(seq,s)\n",
    "        if identity_score <= identity_cutoff:          \n",
    "            if identity_score <= tmp:\n",
    "                out = s\n",
    "                tmp = identity_score\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.read_excel('S5_merge.xlsx')#,sep = None,error_bad_lines=False)\n",
    "\n",
    "df4 = s5.dropna(subset=[\"Sequence\"])\n",
    "\n",
    "grist = pd.read_table('gristone_positive_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "s6 = pd.read_excel('S6_merge.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Modifications</th>\n",
       "      <th>Modifications (all possible sites)</th>\n",
       "      <th>Qvality PEP by SEQUEST</th>\n",
       "      <th>Qvality q-value by FDR</th>\n",
       "      <th>SVM_Score</th>\n",
       "      <th># Protein Groups</th>\n",
       "      <th># Proteins</th>\n",
       "      <th># PSMs</th>\n",
       "      <th>Master Protein Accessions</th>\n",
       "      <th>...</th>\n",
       "      <th>heart</th>\n",
       "      <th>kidney</th>\n",
       "      <th>liver</th>\n",
       "      <th>lung</th>\n",
       "      <th>lymph</th>\n",
       "      <th>ovary</th>\n",
       "      <th>prostate</th>\n",
       "      <th>skeletal_muscle</th>\n",
       "      <th>testes</th>\n",
       "      <th>thyroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KGTQVVKISVHMGRVS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.848500e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.42936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Q7Z7M9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.086017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17426</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.241705</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126499</td>\n",
       "      <td>0.046727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPAHLQTLPVTPNKQKTDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.441770e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Q7Z7M9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.086017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17426</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.241705</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126499</td>\n",
       "      <td>0.046727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HPAHLQTLPVTPNKQKT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.083780e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Q7Z7M9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.086017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17426</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.241705</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126499</td>\n",
       "      <td>0.046727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HPAHLQTLPVTPNKQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.893960e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Q7Z7M9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.086017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17426</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.241705</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126499</td>\n",
       "      <td>0.046727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HPAHLQTLPVTPNKQK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.231250e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.58700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Q7Z7M9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.086017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17426</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.241705</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126499</td>\n",
       "      <td>0.046727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sequence Modifications Modifications (all possible sites)  \\\n",
       "0     KGTQVVKISVHMGRVS           NaN                                NaN   \n",
       "1  HPAHLQTLPVTPNKQKTDG           NaN                                NaN   \n",
       "2    HPAHLQTLPVTPNKQKT           NaN                                NaN   \n",
       "3      HPAHLQTLPVTPNKQ           NaN                                NaN   \n",
       "4     HPAHLQTLPVTPNKQK           NaN                                NaN   \n",
       "\n",
       "   Qvality PEP by SEQUEST  Qvality q-value by FDR  SVM_Score  \\\n",
       "0            5.848500e-08                     0.0    2.42936   \n",
       "1            8.441770e-07                     0.0    2.00900   \n",
       "2            3.083780e-06                     0.0    1.80500   \n",
       "3            5.893960e-06                     0.0    1.70300   \n",
       "4            1.231250e-05                     0.0    1.58700   \n",
       "\n",
       "   # Protein Groups  # Proteins  # PSMs Master Protein Accessions  ...  \\\n",
       "0               1.0         2.0     8.0                    Q7Z7M9  ...   \n",
       "1               1.0         2.0     5.0                    Q7Z7M9  ...   \n",
       "2               1.0         2.0     9.0                    Q7Z7M9  ...   \n",
       "3               1.0         2.0     9.0                    Q7Z7M9  ...   \n",
       "4               1.0         2.0    10.0                    Q7Z7M9  ...   \n",
       "\n",
       "      heart    kidney  liver     lung     lymph     ovary  prostate  \\\n",
       "0  0.100182  0.086017    0.0  3.17426  0.003604  0.241705    0.1607   \n",
       "1  0.100182  0.086017    0.0  3.17426  0.003604  0.241705    0.1607   \n",
       "2  0.100182  0.086017    0.0  3.17426  0.003604  0.241705    0.1607   \n",
       "3  0.100182  0.086017    0.0  3.17426  0.003604  0.241705    0.1607   \n",
       "4  0.100182  0.086017    0.0  3.17426  0.003604  0.241705    0.1607   \n",
       "\n",
       "   skeletal_muscle    testes   thyroid  \n",
       "0              0.0  0.126499  0.046727  \n",
       "1              0.0  0.126499  0.046727  \n",
       "2              0.0  0.126499  0.046727  \n",
       "3              0.0  0.126499  0.046727  \n",
       "4              0.0  0.126499  0.046727  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = s6.dropna(subset=[\"Sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2108"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_set = set(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.130960429000027\n",
      "1945\n"
     ]
    }
   ],
   "source": [
    "df6['neg'] =np.full_like(df6['Sequence'],'o')\n",
    "t0 = time.process_time()\n",
    "matched = 0\n",
    "for i in range(0,len(df6)):\n",
    "#for i in range(0,10000):\n",
    "    g = df6.iloc[i]\n",
    "    ac = set(g['Protein Accessions'].split('; '))\n",
    "    #print(ac)\n",
    "    unique = list(ac & ids_set)\n",
    "    if len(unique) >0:\n",
    "        uni = unique[0]\n",
    "        matched = matched +1\n",
    "        pep = str(g['Sequence'])\n",
    "        full = str(uni_dict[uni].seq)\n",
    "        #pdb.set_trace() \n",
    "        res = filter_with_identity_affinity(pep,full,step=1,identity_cutoff=0.5)\n",
    "\n",
    "        if res != '':\n",
    "            df6.loc[i,'neg'] = res \n",
    "        \n",
    "print(time.process_time()-t0)\n",
    "print(matched)\n",
    "#grist[grist['neg1'] != 'o'].to_csv('testdata0401.txt',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df6[df6['neg'] == 'o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('s6_full_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZhangSan : male\n",
      "LiSi : male\n"
     ]
    }
   ],
   "source": [
    "\n",
    "persons={'ZhangSan':'male',\n",
    "         'LiSi':'male',\n",
    "         'WangHong':'female'}\n",
    "\n",
    "#找出所有男性\n",
    "males = filter(lambda x:'male'== x[1], persons.items())\n",
    "\n",
    "for (key,value) in males:\n",
    "    print('%s : %s' % (key,value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mgrist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Write object to a comma-separated values (csv) file.\n",
       "\n",
       ".. versionchanged:: 0.24.0\n",
       "    The order of arguments for Series was changed.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "path_or_buf : str or file handle, default None\n",
       "    File path or object, if None is provided the result is returned as\n",
       "    a string.  If a file object is passed it should be opened with\n",
       "    `newline=''`, disabling universal newlines.\n",
       "\n",
       "    .. versionchanged:: 0.24.0\n",
       "\n",
       "       Was previously named \"path\" for Series.\n",
       "\n",
       "sep : str, default ','\n",
       "    String of length 1. Field delimiter for the output file.\n",
       "na_rep : str, default ''\n",
       "    Missing data representation.\n",
       "float_format : str, default None\n",
       "    Format string for floating point numbers.\n",
       "columns : sequence, optional\n",
       "    Columns to write.\n",
       "header : bool or list of str, default True\n",
       "    Write out the column names. If a list of strings is given it is\n",
       "    assumed to be aliases for the column names.\n",
       "\n",
       "    .. versionchanged:: 0.24.0\n",
       "\n",
       "       Previously defaulted to False for Series.\n",
       "\n",
       "index : bool, default True\n",
       "    Write row names (index).\n",
       "index_label : str or sequence, or False, default None\n",
       "    Column label for index column(s) if desired. If None is given, and\n",
       "    `header` and `index` are True, then the index names are used. A\n",
       "    sequence should be given if the object uses MultiIndex. If\n",
       "    False do not print fields for index names. Use index_label=False\n",
       "    for easier importing in R.\n",
       "mode : str\n",
       "    Python write mode, default 'w'.\n",
       "encoding : str, optional\n",
       "    A string representing the encoding to use in the output file,\n",
       "    defaults to 'utf-8'.\n",
       "compression : str, default 'infer'\n",
       "    Compression mode among the following possible values: {'infer',\n",
       "    'gzip', 'bz2', 'zip', 'xz', None}. If 'infer' and `path_or_buf`\n",
       "    is path-like, then detect compression from the following\n",
       "    extensions: '.gz', '.bz2', '.zip' or '.xz'. (otherwise no\n",
       "    compression).\n",
       "\n",
       "    .. versionchanged:: 0.24.0\n",
       "\n",
       "       'infer' option added and set to default.\n",
       "\n",
       "quoting : optional constant from csv module\n",
       "    Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
       "    then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
       "    will treat them as non-numeric.\n",
       "quotechar : str, default '\\\"'\n",
       "    String of length 1. Character used to quote fields.\n",
       "line_terminator : str, optional\n",
       "    The newline character or character sequence to use in the output\n",
       "    file. Defaults to `os.linesep`, which depends on the OS in which\n",
       "    this method is called ('\\n' for linux, '\\r\\n' for Windows, i.e.).\n",
       "\n",
       "    .. versionchanged:: 0.24.0\n",
       "chunksize : int or None\n",
       "    Rows to write at a time.\n",
       "date_format : str, default None\n",
       "    Format string for datetime objects.\n",
       "doublequote : bool, default True\n",
       "    Control quoting of `quotechar` inside a field.\n",
       "escapechar : str, default None\n",
       "    String of length 1. Character used to escape `sep` and `quotechar`\n",
       "    when appropriate.\n",
       "decimal : str, default '.'\n",
       "    Character recognized as decimal separator. E.g. use ',' for\n",
       "    European data.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "None or str\n",
       "    If path_or_buf is None, returns the resulting csv format as a\n",
       "    string. Otherwise returns None.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "read_csv : Load a CSV file into a DataFrame.\n",
       "to_excel : Write DataFrame to an Excel file.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
       "...                    'mask': ['red', 'purple'],\n",
       "...                    'weapon': ['sai', 'bo staff']})\n",
       ">>> df.to_csv(index=False)\n",
       "'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grist.to_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%writefile is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
